# Resume Parsing Error and Fix Report

This report details the validation errors occurring in your FastAPI application and provides solutions to fix them.

## 1. Root Cause Analysis

The core issue is that the JSON data generated by your resume parsing logic does not match the data types defined in your Pydantic model, `ResumeData`.

- **Social Links**: The model expects full URLs (e.g., `https://linkedin.com/in/username`), but the parser is returning plain strings like `"LinkedIn"`.
- **Awards**: The model expects a list of simple strings (e.g., `["Award 1", "Award 2"]`), but the parser is returning a list of dictionaries (e.g., `[{"award_name": "Award 1"}, {"award_name": "Award 2"}]`).

## 2. Error Mapping

Here is a breakdown of each validation error:

| Field Path                               | Error                                     | Current (Incorrect) Value        | Expected Type |
| ---------------------------------------- | ----------------------------------------- | -------------------------------- | ------------- |
| `personal_information.social_links.linkedin` | `Input should be a valid URL`             | `'LinkedIn'`                     | `HttpUrl`     |
| `personal_information.social_links.github`   | `Input should be a valid URL`             | `'GitHub'`                       | `HttpUrl`     |
| `personal_information.social_links.portfolio`| `Input should be a valid URL`             | `'Codolio'`                      | `HttpUrl`     |
| `additional_information.awards.0`        | `Input should be a valid string`          | `{'award_name': '...'}`          | `str`         |
| `additional_information.awards.1`        | `Input should be a valid string`          | `{'award_name': '...'}`          | `str`         |

## 3. Solution: Data Transformation

To fix this, you must transform the parsed data *before* it is validated by the `ResumeData` model. The ideal place for this transformation is in your `app/api/resume.py` file, right after you receive the response from your parsing service (e.g., Groq).

Here is a Python function that performs the necessary corrections. You should call this function on the dictionary returned by your parser.

```python
def transform_parsed_data(data: dict) -> dict:
    """
    Corrects the structure and types of parsed resume data to match the Pydantic model.
    """
    # 1. Fix Social Links: Replace placeholder text with None if it's not a URL.
    #    The LLM should ideally return full URLs. If it can't, we must nullify the invalid entries.
    social_links = data.get("personal_information", {}).get("social_links", {})
    if social_links:
        for key, value in social_links.items():
            # A simple check to see if the value is a placeholder or a real URL.
            if not isinstance(value, str) or not value.startswith(('http://', 'https://')):
                social_links[key] = None  # Set to None to pass Pydantic validation for optional fields

    # 2. Fix Awards: Convert a list of dictionaries to a list of strings.
    additional_info = data.get("additional_information", {})
    if additional_info and "awards" in additional_info:
        awards_list = additional_info.get("awards", [])
        if awards_list and isinstance(awards_list[0], dict):
            # Use a list comprehension to extract the 'award_name' from each dictionary.
            corrected_awards = [item.get("award_name", "") for item in awards_list if "award_name" in item]
            additional_info["awards"] = corrected_awards

    return data

# --- How to use it in your API endpoint ---

# In app/api/resume.py

# parsed_json = ... # This is the JSON dictionary from your parser (e.g., Groq)
# corrected_json = transform_parsed_data(parsed_json)

# try:
#     resume_data = ResumeData(**corrected_json)
#     # ... proceed with your logic
# except ValidationError as e:
#     # ... handle error
```

By applying this transformation, the data will align with your Pydantic models, resolving the validation errors.
